Download Data -> Data Exploration and Visualisation -> Justified Cleaning and Imputation of Data

train = pd.read_csv(...)

#Understand the data
train.info()
train.describe()

#Plot histograms (numerical data) and frequency charts (categorical data).
#Investigate unusal distributions

#Histogram for all numerical values
for i in df_num.columns:
  plt.hist(df_num[i])
  plt.title(i)
  plt.show()

#Correlations
print(df_num.corr())
sns.heatmap(df_num.corr())


Types of Seaborn Graphs:
• Distplots (Histograms + automatically calculates appropriate bin sizes)
• JointPlots
• KDE Plot (Smoothed histogram using a continous probability density curve)
• PairPlot (Viewing Correlations; hue=Seperate by Categorical data)
• BarPlot (Categorical x Numerical)
• CountPlot (Counts number of records belonging to a specific category)
• BoxPlot
• JitterPlot (Categorical x Numerical)
• Pivot Table (Counts the number of records between 2 categories. Can be visualised using a heatmap)
• PairGrid (Visualise correlations/Clusters between 2 numerical variables, for categorical value)
All plots: https://seaborn.pydata.org/examples/pointplot_anova.html
Notes:

•SibSp = Number of Siblings/Spouse
•Parch = Number of Parents/Children

•Possible Feature: IsAlone

•Embarked is usually imputated with the mode.

•There are many approaches of handling the Cabin feature. 70%+ of the data is missing.

•Age must also be imputated.

•The Higher a Tourist paid, the higher the chances of survival.

•Encode Strings/Objects into numerical values. (eg. male = 0, female = 1)

•Explore interesting themes: (Wealthy Survive?, By Location, Age Scatterplot with ticket price, Total spent) 




Questions:
•Inthom kontu ħa tneħħu il-Cabin feature?
•Ghamiltu l imputation tal Age?
Zidtu xi columns godda?







• Create Deck Column from first letter of Cabin -> View survival rate per Deck

• Check survival rate with respect to SibSp and Parch
• Check salutation
• remove SibSp and Parch, replace with Family. They are fairly correlated. "highly..."


• https://www.kaggle.com/javigallego/hyperparameter-tuning-ensemble-modeling
• https://towardsdatascience.com/predicting-the-survival-of-titanic-passengers-30870ccc7e8
• https://towardsdatascience.com/a-beginners-guide-to-kaggle-s-titanic-problem-3193cb56f6ca
• Most common algorithms: https://www.kaggle.com/c/titanic/discussion/305960
• https://www.youtube.com/watch?v=I3FBJdiExcg - https://www.kaggle.com/kenjee/titanic-project-example

