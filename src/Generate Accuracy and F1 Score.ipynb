{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the models\n",
    "## Using the full Titanic dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pd.read_csv(os.path.join('..','data','Variant 1','titanic_cleaned.csv'))\n",
    "data2 = pd.read_csv(os.path.join('..','data','Variant 2','titanic_cleaned.csv'))\n",
    "data3 = pd.read_csv(os.path.join('..','data','Variant 3','titanic_cleaned.csv'))\n",
    "data = [data1, data2, data3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "f1scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "done\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "for file in data:\n",
    "    x = file.drop(\"Survived\",axis=1)\n",
    "    y = file[\"Survived\"]\n",
    "    xTrain, xVal, yTrain, yVal = train_test_split(x,y,test_size=0.2,random_state=42)\n",
    "    \n",
    "    #random forest\n",
    "    random_forest = RandomForestClassifier().fit(xTrain,yTrain)\n",
    "    preds = random_forest.predict(xVal)\n",
    "    scores.append(accuracy_score(yVal,preds))\n",
    "    f1scores.append(f1_score(yVal,preds))\n",
    "    \n",
    "    #support vector machine\n",
    "    svm_clf = svm.SVC(kernel='linear').fit(xTrain,yTrain)\n",
    "    preds = svm_clf.predict(xVal)\n",
    "    scores.append(accuracy_score(yVal,preds))\n",
    "    f1scores.append(f1_score(yVal,preds))\n",
    "    \n",
    "    #naive bayes\n",
    "    naive_bayes = GaussianNB().fit(xTrain,yTrain)\n",
    "    preds = naive_bayes.predict(xVal)\n",
    "    scores.append(accuracy_score(yVal,preds))\n",
    "    f1scores.append(f1_score(yVal,preds))\n",
    "    \n",
    "    #decision tree\n",
    "    decision_tree = DecisionTreeClassifier().fit(xTrain,yTrain)\n",
    "    preds = decision_tree.predict(xVal)\n",
    "    scores.append(accuracy_score(yVal,preds))\n",
    "    f1scores.append(f1_score(yVal,preds))\n",
    "    \n",
    "    #logistic regression\n",
    "    logistic_reg = LogisticRegression(max_iter=500).fit(xTrain,yTrain)\n",
    "    preds = logistic_reg.predict(xVal)\n",
    "    scores.append(accuracy_score(yVal,preds))\n",
    "    f1scores.append(f1_score(yVal,preds))\n",
    "    \n",
    "    print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7786259541984732,\n",
       " 0.7557251908396947,\n",
       " 0.7442748091603053,\n",
       " 0.7404580152671756,\n",
       " 0.7786259541984732,\n",
       " 0.8206106870229007,\n",
       " 0.8282442748091603,\n",
       " 0.816793893129771,\n",
       " 0.7938931297709924,\n",
       " 0.8396946564885496,\n",
       " 0.7938931297709924,\n",
       " 0.7977099236641222,\n",
       " 0.7404580152671756,\n",
       " 0.7709923664122137,\n",
       " 0.8206106870229007]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = []\n",
    "for i in range(len(scores)):   \n",
    "    temp = []\n",
    "    if i < 5:\n",
    "         temp.append(1)\n",
    "    elif i > 4 and i < 10:\n",
    "        temp.append(2)\n",
    "    elif i > 9 and 1 < 15:\n",
    "        temp.append(3)\n",
    "        \n",
    "    if i % 5 == 0:\n",
    "        temp.append(\"Random Forest\")\n",
    "    elif i % 5 == 1:\n",
    "        temp.append(\"SVM\")\n",
    "    elif i % 5 == 2:\n",
    "        temp.append(\"Naive Bayes\")\n",
    "    elif i % 5 == 3:\n",
    "        temp.append(\"Decision Tree\")\n",
    "    elif i % 5 == 4:\n",
    "        temp.append(\"Logistic Regression\")\n",
    "        \n",
    "    temp.append(scores[i])\n",
    "    temp.append(f1scores[i])\n",
    "    \n",
    "    l.append(temp)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(l, columns=['Dataset', 'Model', 'Accuracy', 'F1 Score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.778626</td>\n",
       "      <td>0.718447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.755725</td>\n",
       "      <td>0.700935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.744275</td>\n",
       "      <td>0.676329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.740458</td>\n",
       "      <td>0.663366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.778626</td>\n",
       "      <td>0.718447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.820611</td>\n",
       "      <td>0.770732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.828244</td>\n",
       "      <td>0.780488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.816794</td>\n",
       "      <td>0.769231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.793893</td>\n",
       "      <td>0.740385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.839695</td>\n",
       "      <td>0.790000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.793893</td>\n",
       "      <td>0.737864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.797710</td>\n",
       "      <td>0.736318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3</td>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.740458</td>\n",
       "      <td>0.613636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.770992</td>\n",
       "      <td>0.719626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.820611</td>\n",
       "      <td>0.763819</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Dataset                Model  Accuracy  F1 Score\n",
       "0         1        Random Forest  0.778626  0.718447\n",
       "1         1                  SVM  0.755725  0.700935\n",
       "2         1          Naive Bayes  0.744275  0.676329\n",
       "3         1        Decision Tree  0.740458  0.663366\n",
       "4         1  Logistic Regression  0.778626  0.718447\n",
       "5         2        Random Forest  0.820611  0.770732\n",
       "6         2                  SVM  0.828244  0.780488\n",
       "7         2          Naive Bayes  0.816794  0.769231\n",
       "8         2        Decision Tree  0.793893  0.740385\n",
       "9         2  Logistic Regression  0.839695  0.790000\n",
       "10        3        Random Forest  0.793893  0.737864\n",
       "11        3                  SVM  0.797710  0.736318\n",
       "12        3          Naive Bayes  0.740458  0.613636\n",
       "13        3        Decision Tree  0.770992  0.719626\n",
       "14        3  Logistic Regression  0.820611  0.763819"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(os.path.join('..','data','Scores','fullDatasetResults.csv'), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
