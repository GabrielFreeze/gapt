{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2997f94",
   "metadata": {},
   "source": [
    "# Initial testing of machine learning algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cfca1e1",
   "metadata": {},
   "source": [
    "Splitting the dataframe into a training and testing set to train several machine learning and check which one has the highest accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7bfe13f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "\n",
    "import os\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import linear_model\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ce16925c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of training examples: 981\n",
      "No. of testing examples: 328\n"
     ]
    }
   ],
   "source": [
    "complete_df = pd.read_csv(os.path.join('..','..','data',\"Variant 2\",'titanic_cleaned.csv'))\n",
    "\n",
    "train_df, test_df = train_test_split(complete_df, test_size=0.25, random_state=25)\n",
    "print(f\"No. of training examples: {train_df.shape[0]}\")\n",
    "print(f\"No. of testing examples: {test_df.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "20477d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df.drop(\"Survived\", axis=1)\n",
    "Y_train = train_df[\"Survived\"]\n",
    "X_test = test_df.drop(\"Survived\", axis=1)\n",
    "Y_test = test_df[\"Survived\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010243ae",
   "metadata": {},
   "source": [
    "Testing accuracy of the SGD Classifier which generates the worst accuracy from all of the algorithms. Since a new value is generated every time, 1000 cases were taken and a mean and modal value were displayed to show the average and most common accuracies generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "89e6bbb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[60.67, 68.9, 39.94, 60.98, 42.38, 73.78, 60.37, 75.0, 60.37, 74.09, 74.09, 60.37, 61.59, 60.37, 63.41, 67.38, 72.87, 75.3, 70.43, 73.17, 56.71, 43.29, 71.34, 43.29, 74.09, 63.41, 60.37, 72.87, 72.56, 40.24, 72.26, 62.5, 44.51, 60.98, 65.85, 70.73, 39.63, 73.48, 74.7, 75.61, 60.67, 70.12, 41.16, 71.04, 73.17, 59.45, 76.22, 71.95, 70.12, 73.17, 71.04, 36.89, 74.7, 60.37, 73.78, 40.55, 70.73, 60.37, 39.63, 73.48, 55.79, 67.38, 67.38, 60.37, 64.33, 71.65, 72.56, 43.29, 60.37, 73.17, 40.24, 39.63, 40.24, 71.04, 74.7, 73.78, 69.51, 68.9, 63.41, 68.6, 55.79, 64.02, 60.37, 60.37, 42.99, 71.65, 60.37, 70.43, 39.63, 73.48, 58.23, 74.09, 73.17, 69.51, 69.21, 60.37, 60.37, 40.85, 60.37, 74.7, 68.6, 71.34, 76.22, 74.7, 61.89, 61.89, 72.26, 40.24, 69.51, 56.1, 75.0, 73.17, 74.09, 71.34, 71.04, 69.21, 74.7, 70.12, 43.6, 60.37, 61.89, 69.21, 75.91, 70.73, 75.91, 60.37, 71.95, 47.56, 58.23, 73.78, 46.04, 60.37, 66.46, 40.24, 51.22, 71.34, 66.77, 60.37, 53.05, 76.22, 72.26, 76.83, 67.68, 73.48, 72.87, 72.26, 37.2, 65.55, 66.77, 75.3, 67.38, 60.37, 74.39, 60.37, 66.46, 60.37, 60.37, 70.43, 73.17, 39.94, 72.56, 70.43, 60.37, 72.26, 71.95, 39.02, 61.89, 39.94, 64.33, 60.06, 60.37, 75.0, 63.72, 71.95, 73.78, 69.82, 71.04, 74.39, 73.48, 71.34, 75.61, 60.37, 71.34, 68.6, 75.0, 62.2, 67.68, 74.09, 71.95, 55.18, 71.65, 49.7, 67.68, 72.87, 64.63, 60.67, 60.37, 65.85, 70.73, 68.29, 75.0, 69.21, 74.7, 59.45, 47.26, 69.51, 64.02, 69.21, 69.51, 64.94, 60.37, 75.0, 70.73, 60.98, 72.56, 60.67, 67.68, 72.87, 57.62, 69.21, 60.37, 74.39, 71.34, 53.35, 60.67, 39.63, 73.17, 40.55, 41.16, 56.1, 65.55, 74.7, 67.38, 71.95, 68.6, 73.17, 76.22, 60.37, 77.44, 74.7, 55.79, 69.21, 67.99, 72.56, 60.06, 72.87, 72.87, 60.06, 75.91, 72.87, 68.9, 71.04, 67.99, 73.17, 74.39, 69.51, 70.73, 73.78, 60.37, 72.87, 73.17, 70.43, 72.56, 72.26, 73.17, 42.38, 60.37, 67.07, 60.67, 69.21, 70.73, 39.63, 69.21, 44.21, 71.34, 70.43, 75.61, 70.12, 71.34, 37.5, 60.37, 61.59, 74.39, 72.87, 41.77, 60.37, 68.9, 71.65, 59.76, 39.94, 76.22, 71.34, 72.87, 74.09, 68.6, 74.09, 72.87, 60.37, 73.48, 40.55, 67.68, 60.37, 60.37, 73.48, 67.99, 59.76, 73.78, 39.63, 60.37, 40.24, 74.7, 71.34, 46.34, 71.95, 45.73, 69.51, 75.61, 70.73, 60.37, 72.56, 69.51, 70.12, 71.34, 70.73, 71.95, 60.98, 75.0, 40.24, 73.78, 73.17, 69.51, 41.46, 71.65, 49.39, 75.0, 70.43, 40.55, 62.8, 73.48, 56.4, 65.24, 71.34, 72.26, 69.21, 60.37, 62.8, 75.0, 70.73, 76.52, 60.37, 40.24, 68.29, 71.04, 62.2, 73.78, 60.37, 71.04, 72.87, 75.3, 71.04, 60.37, 71.65, 60.37, 72.56, 74.7, 60.67, 60.37, 69.21, 74.09, 58.84, 70.43, 60.37, 70.73, 66.16, 69.82, 72.87, 70.43, 60.37, 75.0, 72.87, 60.37, 75.61, 68.9, 63.41, 60.37, 41.16, 61.89, 65.55, 74.09, 70.12, 71.34, 66.77, 68.9, 71.04, 67.99, 74.09, 60.37, 71.95, 68.9, 68.9, 40.85, 60.37, 71.04, 72.56, 64.94, 71.04, 72.87, 61.59, 71.34, 72.26, 70.73, 71.65, 75.3, 60.37, 71.95, 63.41, 73.17, 75.91, 76.22, 73.48, 70.43, 70.43, 66.77, 60.37, 63.72, 67.68, 60.37, 60.98, 49.39, 64.33, 72.26, 59.76, 66.16, 72.26, 72.87, 73.78, 40.24, 39.63, 60.37, 47.56, 68.29, 71.65, 71.04, 73.78, 58.54, 66.46, 39.94, 34.15, 72.56, 60.37, 70.73, 71.04, 67.99, 58.84, 60.37, 68.29, 71.95, 71.65, 75.61, 60.37, 70.12, 70.43, 73.17, 63.41, 71.34, 60.37, 60.37, 70.73, 40.55, 69.21, 68.29, 72.26, 71.65, 69.51, 68.9, 73.78, 76.22, 60.37, 60.37, 46.95, 75.3, 73.17, 72.56, 69.21, 39.94, 69.21, 60.37, 73.17, 74.39, 60.37, 71.34, 76.22, 66.77, 60.67, 60.37, 67.38, 43.6, 69.21, 60.37, 70.73, 66.46, 60.98, 57.93, 70.73, 71.65, 76.52, 68.29, 48.78, 60.67, 70.73, 68.6, 66.46, 74.39, 61.28, 66.16, 40.24, 65.24, 73.48, 67.68, 67.68, 60.37, 73.78, 39.63, 60.37, 72.26, 74.09, 75.0, 60.37, 75.0, 33.54, 65.55, 41.46, 70.73, 68.9, 45.73, 45.73, 65.85, 42.68, 71.04, 70.12, 76.52, 64.33, 69.51, 72.56, 64.63, 73.17, 74.09, 60.37, 73.48, 60.37, 69.82, 75.91, 67.38, 55.49, 71.65, 62.2, 37.8, 60.37, 75.0, 62.8, 60.67, 39.94, 67.68, 63.72, 40.24, 40.55, 60.67, 73.78, 60.98, 68.6, 52.13, 74.09, 55.49, 60.37, 66.77, 73.17, 43.9, 41.46, 60.37, 70.43, 72.26, 57.93, 77.13, 40.85, 60.67, 74.39, 34.15, 60.37, 60.37, 71.34, 64.33, 75.61, 60.37, 68.6, 73.48, 35.37, 59.76, 60.37, 75.61, 40.55, 60.37, 67.38, 72.87, 42.38, 60.37, 74.39, 74.39, 70.43, 60.67, 54.57, 75.91, 68.9, 71.34, 73.17, 74.7, 73.78, 60.37, 41.16, 61.59, 70.43, 70.12, 60.67, 40.85, 76.52, 47.87, 40.85, 70.43, 69.51, 71.04, 70.12, 67.07, 42.07, 69.21, 73.78, 70.73, 69.21, 74.09, 72.26, 73.17, 52.44, 74.39, 59.76, 75.91, 48.48, 70.12, 75.3, 63.11, 73.48, 60.37, 65.85, 74.39, 40.24, 72.87, 46.34, 71.65, 72.26, 73.17, 40.55, 72.56, 74.7, 63.11, 39.63, 70.73, 75.3, 76.83, 60.37, 70.12, 40.24, 74.7, 60.98, 72.56, 71.65, 71.65, 42.07, 60.37, 61.89, 67.38, 58.84, 60.37, 74.09, 57.01, 60.37, 74.39, 71.65, 68.29, 73.48, 71.34, 48.17, 68.6, 60.37, 52.44, 69.21, 60.37, 74.39, 48.48, 76.52, 75.3, 71.95, 51.22, 68.9, 40.85, 74.39, 73.48, 69.82, 72.26, 72.26, 69.51, 71.04, 60.37, 66.77, 66.16, 75.3, 60.37, 74.09, 61.28, 69.21, 70.12, 74.09, 74.09, 67.07, 69.21, 71.34, 75.91, 74.7, 75.3, 41.46, 72.87, 61.89, 71.65, 75.91, 72.26, 60.37, 76.22, 39.02, 42.07, 71.04, 75.0, 60.37, 75.3, 60.37, 70.43, 42.07, 68.9, 70.12, 67.07, 70.73, 60.37, 72.26, 69.82, 71.04, 67.99, 72.26, 46.34, 40.24, 60.37, 69.82, 72.56, 45.73, 40.55, 67.38, 60.37, 71.65, 70.12, 66.46, 71.95, 70.73, 60.67, 67.68, 60.06, 42.68, 74.39, 59.76, 72.87, 58.54, 70.73, 60.37, 75.0, 72.56, 45.73, 75.3, 60.37, 68.6, 64.63, 72.56, 72.56, 71.34, 75.3, 42.99, 54.27, 50.3, 70.43, 60.37, 72.56, 41.16, 73.48, 75.3, 75.3, 68.9, 60.37, 62.5, 60.37, 60.37, 60.37, 41.16, 74.09, 75.0, 66.16, 42.68, 72.56, 60.98, 71.34, 60.37, 73.48, 69.51, 61.59, 71.95, 60.37, 39.63, 60.37, 40.24, 58.23, 60.37, 43.29, 74.39, 72.56, 72.56, 40.24, 60.37, 71.65, 73.17, 74.39, 70.73, 60.37, 39.94, 72.56, 71.34, 71.95, 71.95, 74.39, 60.37, 69.51, 39.63, 65.85, 69.82, 72.26, 58.84, 73.48, 70.73, 72.56, 74.7, 40.55, 60.37, 75.0, 73.78, 67.99, 60.37, 75.0, 40.24, 40.85, 40.55, 74.39, 75.3, 71.95, 62.2, 69.21, 70.43, 69.21, 71.04, 68.29, 60.37, 33.84, 34.15, 72.56, 74.39, 72.26, 68.6, 60.37, 70.12, 76.52, 69.21, 74.7, 73.48, 40.55, 56.1, 39.94, 74.39, 64.02, 75.91, 60.67, 64.94, 60.67, 73.17, 70.73, 66.16, 60.37, 70.12, 42.68, 67.99, 69.51, 70.73, 64.63, 63.72, 75.3, 74.09, 68.9, 69.51, 75.91, 66.77, 41.16, 66.16, 67.68, 61.89, 75.3, 74.39, 70.43, 60.67, 69.51, 62.5, 69.82, 75.91, 72.26, 68.6, 69.82, 56.71, 33.23, 73.78, 70.12, 72.87, 44.82, 72.87, 39.63, 60.37, 71.34, 68.9, 74.09, 72.26, 73.48, 69.21, 68.6, 60.37, 60.37, 53.66, 69.21, 65.55, 71.65, 66.16, 66.77, 68.9, 56.4, 68.9, 72.87, 70.12, 60.37, 72.56, 67.99, 72.87, 60.37, 70.43, 37.5, 43.9, 68.6, 75.3, 40.55, 71.04, 64.02, 75.91, 69.21, 69.51, 60.37, 72.26, 60.67, 42.99, 60.37, 73.17, 64.94, 75.91, 40.85, 60.37, 71.34, 64.94, 68.29, 61.28, 70.43, 60.98, 72.87, 60.67, 73.48, 60.37, 37.2, 60.37, 70.73, 73.17, 74.09, 69.51, 68.29, 70.43, 73.17, 41.16, 68.9, 41.16]\n"
     ]
    }
   ],
   "source": [
    "sgda =[]\n",
    "i = 0\n",
    "while i < 1000:\n",
    "    #possible solution is to run it multiple times and find the average\n",
    "    sgd = linear_model.SGDClassifier(max_iter=5, tol=None)\n",
    "    sgd.fit(X_train, Y_train)\n",
    "\n",
    "    sgd.score(X_train, Y_train)\n",
    "    sgda.append(round(sgd.score(X_test, Y_test) * 100, 2))\n",
    "    i += 1\n",
    "    \n",
    "print(sgda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5b304500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean value:  64.62877\n",
      "Mode value:  60.37\n"
     ]
    }
   ],
   "source": [
    "import statistics\n",
    "print(\"Mean value: \",statistics.mean(sgda))\n",
    "print(\"Mode value: \",statistics.mode(sgda))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2958b443",
   "metadata": {},
   "source": [
    "This graph depicts how many times an accuracy value was generated form the algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3e8953ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(38.097222222222214, 0.5, 'Count')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sns.histplot(sgda, stat=\"count\", multiple=\"stack\",\n",
    "             kde=False,\n",
    "             element=\"bars\", legend=True)\n",
    "plt.title(\"Model accuracy count\")\n",
    "plt.xlabel(\"Accuracy\")\n",
    "plt.ylabel(\"Count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f08eead",
   "metadata": {},
   "source": [
    "Testing accuracy of the KNN Classifier which generates the second best accuracy from all of the algorithms with 13 neighbours providing the highest accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "274b6360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70.12\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors = 13) \n",
    "knn.fit(X_train, Y_train)  \n",
    "knnR = round(knn.score(X_test, Y_test) * 100, 2)\n",
    "print(knnR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4bf2d68",
   "metadata": {},
   "source": [
    "Testing accuracy of the Random Forest Classifier which generates the highest accuracy from all of the algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e57ad9b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95.82\n"
     ]
    }
   ],
   "source": [
    "random_forest = RandomForestClassifier(n_estimators=100)\n",
    "random_forest.fit(X_train, Y_train)\n",
    "\n",
    "random_forest.score(X_test, Y_test)\n",
    "acc_random_forest = round(random_forest.score(X_train, Y_train) * 100, 2)\n",
    "\n",
    "print(acc_random_forest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d046422e",
   "metadata": {},
   "source": [
    "Sources: https://towardsdatascience.com/predicting-the-survival-of-titanic-passengers-30870ccc7e8\n",
    "         https://www.kaggle.com/code/allohvk/titanic-missing-age-imputation-tutorial-advanced/notebook"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gapt-venv",
   "language": "python",
   "name": "gapt-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
