{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2997f94",
   "metadata": {},
   "source": [
    "# Initial testing of machine learning algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cfca1e1",
   "metadata": {},
   "source": [
    "Splitting the dataframe into a training and testing set to train several machine learning and check which one has the highest accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7bfe13f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "\n",
    "import os\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import linear_model\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce16925c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of training examples: 981\n",
      "No. of testing examples: 328\n"
     ]
    }
   ],
   "source": [
    "complete_df = pd.read_csv(os.path.join('..','..','data',\"Variant 2\",'titanic_cleaned.csv'))\n",
    "\n",
    "train_df, test_df = train_test_split(complete_df, test_size=0.25, random_state=25)\n",
    "print(f\"No. of training examples: {train_df.shape[0]}\")\n",
    "print(f\"No. of testing examples: {test_df.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20477d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df.drop(\"Survived\", axis=1)\n",
    "Y_train = train_df[\"Survived\"]\n",
    "X_test = test_df.drop(\"Survived\", axis=1)\n",
    "Y_test = test_df[\"Survived\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010243ae",
   "metadata": {},
   "source": [
    "Testing accuracy of the SGD Classifier which generates the worst accuracy from all of the algorithms. Since a new value is generated every time, 1000 cases were taken and a mean and modal value were displayed to show the average and most common accuracies generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89e6bbb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[60.37, 60.67, 41.77, 54.27, 75.61, 72.56, 39.63, 71.95, 37.5, 65.24, 60.67, 60.37, 75.3, 72.87, 60.98, 71.34, 57.01, 67.38, 60.37, 71.95, 40.24, 68.6, 67.99, 68.29, 60.37, 71.65, 70.12, 72.56, 72.26, 73.48, 74.39, 41.46, 45.12, 60.37, 68.29, 73.48, 60.37, 76.22, 39.63, 58.84, 71.04, 73.17, 75.0, 71.95, 75.0, 66.46, 74.7, 41.16, 40.24, 62.2, 72.87, 61.28, 60.37, 75.91, 70.12, 39.63, 70.73, 59.15, 71.95, 73.17, 72.26, 71.95, 40.85, 68.6, 71.34, 70.73, 75.61, 72.26, 41.16, 71.34, 68.29, 72.56, 59.45, 60.37, 58.54, 75.0, 60.37, 75.3, 42.68, 73.48, 71.04, 71.34, 73.48, 72.87, 59.45, 72.87, 71.04, 73.78, 60.37, 72.56, 71.04, 73.17, 57.32, 60.37, 63.72, 68.9, 69.51, 60.06, 43.6, 60.37, 69.82, 42.68, 71.04, 68.9, 70.12, 63.72, 60.37, 71.04, 71.04, 72.56, 56.71, 69.21, 71.95, 67.68, 41.16, 65.24, 69.21, 60.37, 73.17, 63.72, 71.04, 40.55, 68.9, 60.67, 75.91, 75.91, 74.39, 75.0, 50.0, 73.17, 71.34, 64.94, 74.39, 74.39, 68.6, 66.16, 71.34, 70.43, 57.93, 64.63, 75.0, 68.29, 61.59, 69.82, 74.09, 71.04, 60.37, 60.98, 69.21, 60.67, 70.73, 73.48, 49.09, 39.63, 71.04, 39.63, 60.37, 58.23, 67.99, 57.93, 60.37, 70.73, 44.21, 69.82, 43.29, 41.46, 60.37, 40.55, 74.39, 70.73, 71.34, 50.91, 60.67, 71.95, 75.61, 60.37, 44.21, 60.37, 34.76, 66.77, 69.21, 70.43, 71.34, 72.87, 72.56, 60.37, 72.87, 71.34, 39.63, 39.94, 59.76, 67.38, 41.77, 70.43, 42.38, 45.43, 69.51, 72.56, 39.63, 75.3, 71.04, 39.63, 75.3, 64.63, 58.23, 46.34, 71.65, 60.37, 71.95, 46.95, 64.02, 71.04, 70.43, 70.43, 68.6, 60.37, 60.67, 70.43, 40.24, 72.87, 39.63, 60.37, 61.59, 60.37, 60.37, 69.82, 72.56, 70.43, 46.95, 72.87, 69.51, 75.0, 60.67, 71.04, 39.94, 74.09, 71.04, 72.56, 69.51, 71.04, 76.52, 70.43, 70.73, 68.29, 40.24, 71.34, 74.39, 41.16, 73.17, 69.51, 60.37, 76.83, 74.7, 65.24, 68.9, 70.73, 69.82, 42.68, 75.3, 33.23, 60.37, 39.94, 70.73, 60.37, 68.9, 45.12, 70.43, 69.82, 69.82, 60.37, 70.12, 71.65, 60.37, 60.67, 76.22, 60.37, 53.96, 39.63, 39.94, 70.12, 60.37, 54.88, 60.37, 75.61, 73.48, 73.78, 60.37, 62.2, 66.77, 41.16, 74.39, 71.65, 75.0, 40.55, 74.7, 45.43, 68.29, 72.56, 74.09, 60.37, 74.09, 75.91, 60.37, 74.39, 60.37, 71.34, 72.87, 39.94, 74.7, 46.65, 74.09, 77.44, 73.78, 67.07, 58.54, 71.95, 67.68, 73.78, 70.43, 71.65, 37.8, 72.87, 42.38, 68.29, 61.89, 40.85, 75.61, 74.39, 68.29, 38.41, 72.87, 72.56, 71.04, 60.37, 71.65, 71.95, 70.43, 60.37, 71.65, 71.04, 60.37, 39.63, 60.37, 73.48, 71.95, 67.99, 40.55, 43.6, 70.73, 71.34, 73.78, 75.0, 69.51, 75.3, 74.7, 64.33, 73.17, 64.63, 62.5, 72.26, 70.43, 74.09, 74.39, 52.13, 71.04, 44.21, 58.54, 39.63, 74.09, 75.91, 60.37, 75.3, 72.26, 71.04, 75.3, 39.94, 71.65, 64.02, 59.76, 72.26, 70.73, 60.67, 40.85, 71.04, 37.5, 56.71, 74.7, 73.78, 74.09, 77.44, 41.77, 71.95, 60.37, 67.68, 73.78, 62.2, 72.87, 50.61, 59.76, 72.87, 42.38, 71.04, 69.51, 41.46, 73.48, 61.28, 74.39, 73.78, 57.62, 70.43, 70.73, 73.48, 66.77, 71.65, 74.7, 75.3, 73.78, 39.94, 69.51, 73.78, 68.9, 71.95, 64.94, 60.67, 71.65, 59.76, 68.9, 42.99, 60.37, 39.63, 51.83, 72.87, 60.37, 41.16, 41.77, 70.73, 72.87, 71.95, 68.9, 73.17, 40.85, 74.39, 60.37, 60.98, 72.87, 73.78, 70.73, 72.26, 73.17, 60.37, 71.34, 60.37, 73.78, 73.17, 42.07, 49.7, 74.09, 70.73, 73.78, 60.37, 42.68, 74.7, 70.43, 42.38, 76.22, 71.04, 74.39, 73.48, 72.26, 68.9, 39.63, 73.48, 69.82, 71.34, 40.24, 71.95, 74.09, 72.87, 69.21, 60.37, 47.26, 71.65, 73.48, 69.82, 39.94, 72.56, 69.82, 70.12, 76.22, 59.45, 75.61, 69.21, 60.98, 50.61, 71.04, 68.9, 62.5, 60.37, 74.7, 71.04, 71.65, 60.98, 56.71, 65.85, 72.56, 60.67, 71.04, 72.87, 70.73, 72.26, 41.77, 48.17, 69.21, 60.98, 70.12, 69.82, 63.41, 67.68, 71.65, 72.56, 76.52, 68.29, 59.15, 58.23, 75.0, 60.98, 56.1, 71.65, 71.04, 75.3, 69.51, 75.0, 70.73, 40.24, 76.22, 72.87, 72.26, 75.0, 75.91, 71.65, 72.87, 71.34, 41.77, 74.7, 40.55, 76.52, 75.3, 68.6, 68.6, 77.44, 70.73, 69.82, 68.9, 68.29, 60.37, 58.23, 39.02, 71.65, 60.37, 40.85, 74.39, 70.73, 60.37, 67.38, 49.09, 74.09, 72.26, 61.28, 71.95, 71.04, 56.1, 38.11, 56.4, 70.43, 60.37, 75.61, 70.12, 71.95, 60.37, 66.16, 71.04, 64.94, 60.67, 69.51, 61.59, 63.72, 60.37, 77.13, 70.43, 68.29, 68.6, 73.17, 73.17, 67.99, 70.43, 71.95, 72.56, 71.65, 63.72, 69.21, 70.73, 73.17, 65.24, 68.9, 60.37, 60.37, 72.26, 64.02, 60.67, 43.29, 60.67, 70.43, 73.17, 70.43, 71.65, 71.95, 73.78, 69.51, 42.07, 75.91, 62.5, 65.24, 71.34, 43.29, 57.62, 60.37, 65.55, 60.37, 59.15, 68.6, 58.84, 60.37, 60.37, 72.87, 72.87, 60.37, 66.46, 60.37, 70.12, 41.77, 71.34, 67.68, 64.33, 68.6, 44.21, 67.07, 60.37, 69.51, 41.46, 57.62, 60.37, 73.78, 73.48, 74.09, 40.85, 69.21, 70.12, 64.33, 73.48, 54.27, 69.51, 72.56, 60.67, 39.63, 45.43, 68.9, 66.16, 60.37, 32.62, 60.37, 68.9, 60.06, 60.37, 64.94, 71.04, 73.17, 60.37, 75.0, 60.98, 74.7, 71.04, 42.07, 65.55, 67.38, 60.37, 60.37, 43.29, 70.73, 75.0, 72.56, 74.7, 76.22, 60.37, 39.63, 60.67, 39.63, 68.9, 75.0, 60.37, 62.2, 68.6, 71.95, 71.65, 73.48, 40.55, 65.85, 68.9, 60.37, 68.9, 76.22, 60.37, 72.56, 75.3, 47.56, 73.78, 76.22, 73.17, 73.48, 75.91, 72.87, 74.09, 59.45, 73.17, 69.21, 69.21, 75.91, 72.26, 60.37, 74.39, 60.37, 60.37, 64.33, 40.55, 68.6, 72.56, 70.12, 60.67, 70.73, 71.04, 61.59, 72.26, 61.59, 73.48, 69.21, 60.98, 65.24, 70.12, 72.26, 75.0, 76.22, 69.51, 74.09, 68.9, 76.22, 72.56, 69.51, 70.12, 71.04, 72.87, 69.82, 57.32, 71.65, 62.5, 40.55, 71.04, 72.87, 60.37, 73.78, 69.51, 75.0, 56.1, 64.63, 71.95, 73.48, 73.17, 64.94, 42.07, 73.78, 61.89, 64.33, 64.33, 60.37, 77.13, 40.55, 60.37, 69.51, 75.0, 40.85, 69.21, 69.21, 60.98, 75.91, 68.6, 62.8, 69.21, 76.22, 72.56, 39.63, 60.37, 39.63, 70.43, 70.73, 70.73, 64.94, 64.33, 72.87, 70.12, 64.63, 74.7, 72.26, 48.17, 67.99, 53.66, 68.9, 68.29, 71.34, 75.3, 68.29, 60.37, 73.17, 69.21, 66.77, 40.85, 70.73, 60.67, 72.56, 75.91, 60.06, 66.77, 64.33, 69.82, 69.51, 60.37, 70.43, 73.78, 55.79, 66.77, 71.95, 49.39, 72.26, 60.37, 72.87, 68.6, 71.65, 72.87, 73.48, 72.56, 70.73, 73.48, 73.48, 72.56, 69.51, 61.89, 70.73, 33.84, 39.94, 68.29, 56.4, 72.26, 60.37, 72.26, 56.71, 67.68, 43.6, 60.37, 60.37, 72.56, 67.07, 40.24, 72.56, 71.04, 60.37, 55.79, 74.7, 66.77, 72.26, 39.63, 55.49, 72.87, 71.65, 66.16, 73.78, 72.87, 65.55, 39.63, 60.37, 40.55, 61.89, 71.65, 60.37, 69.51, 60.37, 70.73, 72.87, 72.56, 70.73, 73.17, 40.55, 69.21, 69.21, 58.84, 61.59, 75.3, 71.34, 39.63, 73.48, 71.04, 60.37, 69.51, 71.95, 72.56, 67.68, 73.17, 60.37, 74.39, 69.82, 61.59, 60.37, 68.6, 72.56, 67.07, 66.16, 75.61, 66.16, 72.56, 67.68, 32.93, 60.37, 69.82, 72.26, 68.9, 39.63, 69.82, 74.09, 70.43, 68.29, 62.2, 73.17, 69.82, 72.26, 75.3, 39.94, 70.43, 72.56, 72.87, 73.78, 42.38, 72.87, 60.37, 64.33, 70.12, 55.18, 68.9, 64.02, 70.73, 72.87, 75.61, 60.37, 72.56, 72.87, 47.26, 75.0, 75.91, 43.29, 68.6, 75.91, 40.24, 60.37, 71.04, 40.85, 35.37, 71.65, 53.66, 72.26, 58.84, 67.99, 64.02, 72.87, 71.04, 68.6, 70.12, 60.37, 71.04, 57.32, 71.95, 40.24, 74.7, 59.45, 69.82, 60.37, 67.38, 73.78, 60.37, 70.12, 60.37, 60.37, 73.48, 68.29, 70.73, 71.04]\n"
     ]
    }
   ],
   "source": [
    "model_a =[]\n",
    "i = 0\n",
    "while i < 1000:\n",
    "    #possible solution is to run it multiple times and find the average\n",
    "    model = linear_model.SGDClassifier(max_iter=5, tol=None)\n",
    "    model.fit(X_train, Y_train)\n",
    "\n",
    "    model.score(X_train, Y_train)\n",
    "    model_a.append(round(model.score(X_test, Y_test) * 100, 2))\n",
    "    i += 1\n",
    "    \n",
    "print(model_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b304500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean value:  64.7258\n",
      "Mode value:  60.37\n"
     ]
    }
   ],
   "source": [
    "import statistics\n",
    "print(\"Mean value: \",statistics.mean(model_a))\n",
    "print(\"Mode value: \",statistics.mode(model_a))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2958b443",
   "metadata": {},
   "source": [
    "This graph depicts how many times an accuracy value was generated form the algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e8953ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Count')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sns.histplot(model_a, stat=\"count\", multiple=\"stack\",\n",
    "             kde=False,\n",
    "             element=\"bars\", legend=True)\n",
    "plt.title(\"Model accuracy count\")\n",
    "plt.xlabel(\"Accuracy\")\n",
    "plt.ylabel(\"Count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f08eead",
   "metadata": {},
   "source": [
    "Testing accuracy of the KNN Classifier which generates the second best accuracy from all of the algorithms with 13 neighbours providing the highest accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "274b6360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70.12\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors = 13) \n",
    "knn.fit(X_train, Y_train)  \n",
    "knnR = round(knn.score(X_test, Y_test) * 100, 2)\n",
    "print(knnR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4bf2d68",
   "metadata": {},
   "source": [
    "Testing accuracy of the Random Forest Classifier which generates the highest accuracy from all of the algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e57ad9b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95.82\n"
     ]
    }
   ],
   "source": [
    "random_forest = RandomForestClassifier(n_estimators=100)\n",
    "random_forest.fit(X_train, Y_train)\n",
    "\n",
    "random_forest.score(X_test, Y_test)\n",
    "acc_random_forest = round(random_forest.score(X_train, Y_train) * 100, 2)\n",
    "\n",
    "print(acc_random_forest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d046422e",
   "metadata": {},
   "source": [
    "Sources: https://towardsdatascience.com/predicting-the-survival-of-titanic-passengers-30870ccc7e8\n",
    "         https://www.kaggle.com/code/allohvk/titanic-missing-age-imputation-tutorial-advanced/notebook"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gapt-venv",
   "language": "python",
   "name": "gapt-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
